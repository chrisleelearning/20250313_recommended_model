{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZSCFOrIEpp2",
        "outputId": "fa78b5ba-2e85-455b-d5c2-bd227990b0c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import urllib.request\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "s9uQ0xMaEptG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# 1. 下載並解壓 MovieLens 100K 資料\n",
        "#######################################\n",
        "\n",
        "data_url = \"https://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
        "zip_path = \"ml-100k.zip\"\n",
        "if not os.path.exists(zip_path):\n",
        "    print(\"Downloading dataset...\")\n",
        "    urllib.request.urlretrieve(data_url, zip_path)\n",
        "\n",
        "if not os.path.exists(\"ml-100k\"):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(\".\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC37bAN1ExIb",
        "outputId": "1d4f107d-278e-4683-8274-7f01fae68b21"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Extracting dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# 2. 載入並預處理資料 (u.data)\n",
        "#######################################\n",
        "\n",
        "data_path = \"ml-100k/u.data\"  # 解壓後路徑\n",
        "df = pd.read_csv(data_path, sep='\\t', header=None, names=['user', 'item', 'rating', 'timestamp'])\n",
        "# 二值化評分 (rating>=4 為正樣本)\n",
        "df['label'] = (df['rating'] >= 4).astype(np.float32)\n",
        "\n",
        "# 建立使用者與物品索引（連續整數）\n",
        "user_ids = df['user'].unique()\n",
        "item_ids = df['item'].unique()\n",
        "num_users = len(user_ids)\n",
        "num_items = len(item_ids)\n",
        "\n",
        "user2idx = {uid: idx for idx, uid in enumerate(user_ids)}\n",
        "item2idx = {iid: idx for idx, iid in enumerate(item_ids)}\n",
        "df['user_idx'] = df['user'].apply(lambda x: user2idx[x])\n",
        "df['item_idx'] = df['item'].apply(lambda x: item2idx[x])\n",
        "\n",
        "# 切分訓練與測試資料\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Aa_EQyfhFfi0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# 3. 定義 Dataset 與 DataLoader (PyTorch)\n",
        "#######################################\n",
        "\n",
        "class RecDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.users = df['user_idx'].values\n",
        "        self.items = df['item_idx'].values\n",
        "        self.labels = df['label'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'user': torch.tensor(self.users[idx], dtype=torch.long),\n",
        "            'item': torch.tensor(self.items[idx], dtype=torch.long),\n",
        "            'label': torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        }\n",
        "\n",
        "batch_size = 256\n",
        "train_dataset = RecDataset(train_df)\n",
        "test_dataset = RecDataset(test_df)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "TWdECSXAFfk9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# 4. 為 LightGCN 建構歸一化稀疏鄰接矩陣\n",
        "#######################################\n",
        "\n",
        "def build_norm_adj(train_data, num_users, num_items):\n",
        "    # 建立 user-item 交互的 bipartite graph\n",
        "    rows = np.array(train_data['user_idx'].tolist() + (train_data['item_idx'] + num_users).tolist())\n",
        "    cols = np.array(train_data['item_idx'] + num_users).tolist() + train_data['user_idx'].tolist()\n",
        "    data = np.ones(len(rows))\n",
        "    adj = sp.coo_matrix((data, (rows, cols)), shape=(num_users + num_items, num_users + num_items))\n",
        "\n",
        "    # 計算 D^(-1/2)\n",
        "    rowsum = np.array(adj.sum(1)).flatten()\n",
        "    d_inv_sqrt = np.power(rowsum, -0.5)\n",
        "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
        "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
        "\n",
        "    norm_adj = d_mat_inv_sqrt.dot(adj).dot(d_mat_inv_sqrt).tocoo()\n",
        "    # 轉成 torch.sparse.FloatTensor\n",
        "    indices = torch.from_numpy(np.vstack((norm_adj.row, norm_adj.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(norm_adj.data.astype(np.float32))\n",
        "    shape = torch.Size(norm_adj.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)\n",
        "\n",
        "norm_adj = build_norm_adj(train_df, num_users, num_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWF6UwlJFfnV",
        "outputId": "87fabb56-076a-41d9-a054-9af7e82fdf00"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-5aca32750700>:14: RuntimeWarning: divide by zero encountered in power\n",
            "  d_inv_sqrt = np.power(rowsum, -0.5)\n",
            "<ipython-input-8-5aca32750700>:23: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:651.)\n",
            "  return torch.sparse.FloatTensor(indices, values, shape)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# 5. 定義模型\n",
        "#######################################\n",
        "\n",
        "# 5-1. NCF 模型\n",
        "class NCF(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embed_dim=32, hidden_dims=[64, 32, 16, 8]):\n",
        "        super(NCF, self).__init__()\n",
        "        self.user_embed = nn.Embedding(num_users, embed_dim)\n",
        "        self.item_embed = nn.Embedding(num_items, embed_dim)\n",
        "\n",
        "        layers = []\n",
        "        input_size = embed_dim * 2\n",
        "        for hidden in hidden_dims:\n",
        "            layers.append(nn.Linear(input_size, hidden))\n",
        "            layers.append(nn.ReLU())\n",
        "            input_size = hidden\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output_layer = nn.Linear(input_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, user, item):\n",
        "        user_emb = self.user_embed(user)\n",
        "        item_emb = self.item_embed(item)\n",
        "        x = torch.cat([user_emb, item_emb], dim=-1)\n",
        "        x = self.mlp(x)\n",
        "        x = self.output_layer(x)\n",
        "        return self.sigmoid(x).squeeze()\n",
        "\n",
        "# 5-2. LightGCN 模型\n",
        "class LightGCN(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embed_dim=32, n_layers=2, norm_adj=None):\n",
        "        super(LightGCN, self).__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.embed_dim = embed_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.norm_adj = norm_adj  # 預先計算好的歸一化鄰接矩陣\n",
        "\n",
        "        # 初始化使用者與物品 embedding\n",
        "        self.user_embed = nn.Embedding(num_users, embed_dim)\n",
        "        self.item_embed = nn.Embedding(num_items, embed_dim)\n",
        "        nn.init.xavier_uniform_(self.user_embed.weight)\n",
        "        nn.init.xavier_uniform_(self.item_embed.weight)\n",
        "\n",
        "    def computer(self):\n",
        "        # 將使用者與物品的 embedding 串接\n",
        "        all_embeddings = torch.cat([self.user_embed.weight, self.item_embed.weight], dim=0)\n",
        "        embeddings_list = [all_embeddings]\n",
        "        for layer in range(self.n_layers):\n",
        "            all_embeddings = torch.sparse.mm(self.norm_adj, all_embeddings)\n",
        "            embeddings_list.append(all_embeddings)\n",
        "        # 取各層平均\n",
        "        final_embedding = torch.stack(embeddings_list, dim=1).mean(dim=1)\n",
        "        user_final, item_final = torch.split(final_embedding, [self.num_users, self.num_items], dim=0)\n",
        "        return user_final, item_final\n",
        "\n",
        "    def forward(self, users, items):\n",
        "        user_emb, item_emb = self.computer()\n",
        "        u_e = user_emb[users]\n",
        "        i_e = item_emb[items]\n",
        "        logits = (u_e * i_e).sum(dim=1)\n",
        "        return torch.sigmoid(logits)"
      ],
      "metadata": {
        "id": "DhAdutHBFtmt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# 6. 定義訓練與評估函式（供深度模型使用）\n",
        "#######################################\n",
        "\n",
        "def train_model(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for batch in train_loader:\n",
        "        user = batch['user'].to(device)\n",
        "        item = batch['item'].to(device)\n",
        "        label = batch['label'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(user, item)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item() * user.size(0)\n",
        "    return epoch_loss / len(train_loader.dataset)\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            user = batch['user'].to(device)\n",
        "            item = batch['item'].to(device)\n",
        "            label = batch['label'].to(device)\n",
        "            output = model(user, item)\n",
        "            preds = (output >= 0.5).float()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(label.cpu().numpy())\n",
        "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "_8HRSaCwFtpJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# 7. 設定裝置與超參數，訓練深度模型\n",
        "#######################################\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_epochs = 10\n",
        "lr = 0.001\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# 7-1. 訓練 NCF\n",
        "ncf_model = NCF(num_users, num_items).to(device)\n",
        "optimizer_ncf = torch.optim.Adam(ncf_model.parameters(), lr=lr)\n",
        "print(\"Training NCF...\")\n",
        "for epoch in range(n_epochs):\n",
        "    loss = train_model(ncf_model, train_loader, optimizer_ncf, criterion, device)\n",
        "    acc = evaluate_model(ncf_model, test_loader, device)\n",
        "    print(f\"NCF Epoch {epoch+1}/{n_epochs} - Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n",
        "ncf_acc = evaluate_model(ncf_model, test_loader, device)\n",
        "\n",
        "# 7-2. 訓練 LightGCN\n",
        "lightgcn_model = LightGCN(num_users, num_items, norm_adj=norm_adj.to(device)).to(device)\n",
        "optimizer_lg = torch.optim.Adam(lightgcn_model.parameters(), lr=lr)\n",
        "print(\"\\nTraining LightGCN...\")\n",
        "for epoch in range(n_epochs):\n",
        "    loss = train_model(lightgcn_model, train_loader, optimizer_lg, criterion, device)\n",
        "    acc = evaluate_model(lightgcn_model, test_loader, device)\n",
        "    print(f\"LightGCN Epoch {epoch+1}/{n_epochs} - Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n",
        "lg_acc = evaluate_model(lightgcn_model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1DYtOs4Ftrc",
        "outputId": "9ab1249e-689c-44f3-e3d5-e11fca90b9b7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training NCF...\n",
            "NCF Epoch 1/10 - Loss: 0.6705, Test Accuracy: 0.6260\n",
            "NCF Epoch 2/10 - Loss: 0.6167, Test Accuracy: 0.6613\n",
            "NCF Epoch 3/10 - Loss: 0.5846, Test Accuracy: 0.6798\n",
            "NCF Epoch 4/10 - Loss: 0.5653, Test Accuracy: 0.6858\n",
            "NCF Epoch 5/10 - Loss: 0.5520, Test Accuracy: 0.6891\n",
            "NCF Epoch 6/10 - Loss: 0.5406, Test Accuracy: 0.6909\n",
            "NCF Epoch 7/10 - Loss: 0.5320, Test Accuracy: 0.6932\n",
            "NCF Epoch 8/10 - Loss: 0.5239, Test Accuracy: 0.6912\n",
            "NCF Epoch 9/10 - Loss: 0.5167, Test Accuracy: 0.6919\n",
            "NCF Epoch 10/10 - Loss: 0.5089, Test Accuracy: 0.6908\n",
            "\n",
            "Training LightGCN...\n",
            "LightGCN Epoch 1/10 - Loss: 0.6782, Test Accuracy: 0.5622\n",
            "LightGCN Epoch 2/10 - Loss: 0.6389, Test Accuracy: 0.6085\n",
            "LightGCN Epoch 3/10 - Loss: 0.6240, Test Accuracy: 0.6246\n",
            "LightGCN Epoch 4/10 - Loss: 0.6158, Test Accuracy: 0.6349\n",
            "LightGCN Epoch 5/10 - Loss: 0.6101, Test Accuracy: 0.6390\n",
            "LightGCN Epoch 6/10 - Loss: 0.6058, Test Accuracy: 0.6424\n",
            "LightGCN Epoch 7/10 - Loss: 0.6023, Test Accuracy: 0.6469\n",
            "LightGCN Epoch 8/10 - Loss: 0.5993, Test Accuracy: 0.6469\n",
            "LightGCN Epoch 9/10 - Loss: 0.5967, Test Accuracy: 0.6487\n",
            "LightGCN Epoch 10/10 - Loss: 0.5943, Test Accuracy: 0.6501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# 8. 準備 XGBoost 與 LightGBM 的資料\n",
        "#######################################\n",
        "# 對於樹模型，採用 one-hot encoding 方式產生特徵 (使用 user_idx 與 item_idx)\n",
        "def prepare_tree_features(df):\n",
        "    df_feat = df.copy()\n",
        "    user_dummies = pd.get_dummies(df_feat['user_idx'], prefix='user')\n",
        "    item_dummies = pd.get_dummies(df_feat['item_idx'], prefix='item')\n",
        "    df_feat = pd.concat([df_feat, user_dummies, item_dummies], axis=1)\n",
        "    # 特徵欄位為所有 one-hot 的欄位\n",
        "    feature_cols = list(user_dummies.columns) + list(item_dummies.columns)\n",
        "    return df_feat[feature_cols], df_feat['label']\n",
        "\n",
        "X_train, y_train = prepare_tree_features(train_df)\n",
        "X_test, y_test = prepare_tree_features(test_df)\n",
        "# reindex 測試資料，確保與訓練資料的欄位一致\n",
        "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n"
      ],
      "metadata": {
        "id": "4-Tp8UZUFtt1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# 9. 訓練 XGBoost 與 LightGBM\n",
        "#######################################\n",
        "\n",
        "print(\"\\nTraining XGBoost...\")\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_preds = xgb_model.predict(X_test)\n",
        "xgb_acc = accuracy_score(y_test, xgb_preds)\n",
        "print(f\"XGBoost Test Accuracy: {xgb_acc:.4f}\")\n",
        "\n",
        "print(\"\\nTraining LightGBM...\")\n",
        "lgb_model = LGBMClassifier()\n",
        "lgb_model.fit(X_train, y_train)\n",
        "lgb_preds = lgb_model.predict(X_test)\n",
        "lgb_acc = accuracy_score(y_test, lgb_preds)\n",
        "print(f\"LightGBM Test Accuracy: {lgb_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laRXCG0lFtwT",
        "outputId": "9806d4f6-1a26-4af2-ed3d-da900d7c4348"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:07:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Test Accuracy: 0.6483\n",
            "\n",
            "Training LightGBM...\n",
            "[LightGBM] [Info] Number of positive: 44385, number of negative: 35615\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.671113 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3400\n",
            "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 1700\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554813 -> initscore=0.220135\n",
            "[LightGBM] [Info] Start training from score 0.220135\n",
            "LightGBM Test Accuracy: 0.6633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# 10. 統一比較各模型結果\n",
        "#######################################\n",
        "print(\"\\n=== Quantitative Comparison ===\")\n",
        "print(f\"NCF Test Accuracy: {ncf_acc:.4f}\")\n",
        "print(f\"LightGCN Test Accuracy: {lg_acc:.4f}\")\n",
        "print(f\"XGBoost Test Accuracy: {xgb_acc:.4f}\")\n",
        "print(f\"LightGBM Test Accuracy: {lgb_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d80yAbukFtyp",
        "outputId": "c7c8d840-e1f2-46c8-defc-405e6810ead5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Quantitative Comparison ===\n",
            "NCF Test Accuracy: 0.6908\n",
            "LightGCN Test Accuracy: 0.6501\n",
            "XGBoost Test Accuracy: 0.6483\n",
            "LightGBM Test Accuracy: 0.6633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HeuKnJ3DFfpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pya1owOJExKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iyq68_5nExNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rr0b3eo1ExPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jH7gvwTQExR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vhR_wYDKExUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-lgVJ1NZExWt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}